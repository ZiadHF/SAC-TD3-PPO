#!/usr/bin/env python3
"""
CMPS458 Assignment 4 - Autonomous RL Training Master
This script runs ALL experiments unattended with crash recovery.
Usage: nohup python run_master.py > master.log 2>&1 &
"""

import os
import sys
import time
import yaml
import torch
import shutil
import argparse
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any
import traceback

# ==================== CONFIGURATION ====================

YOUR_HF_USERNAME = "ZiadHF" 
HF_TOKEN = os.getenv("HF_TOKEN")
WANDB_PROJECT = "cmps458-assignment4_3"

# All experiments to run
EXPERIMENTS = [
    {"algo": "sac", "env": "LunarLander-v3", "config": "configs/sac_lunarlander.yaml", "priority": 1},
    {"algo": "td3", "env": "LunarLander-v3", "config": "configs/td3_lunarlander.yaml", "priority": 2},
    {"algo": "ppo", "env": "LunarLander-v3", "config": "configs/ppo_lunarlander.yaml", "priority": 3},
    {"algo": "sac_cnn", "env": "CarRacing-v3", "config": "configs/sac_carracing.yaml", "priority": 4},
    {"algo": "td3_cnn", "env": "CarRacing-v3", "config": "configs/td3_carracing.yaml", "priority": 5},
    {"algo": "ppo_cnn", "env": "CarRacing-v3", "config": "configs/ppo_carracing.yaml", "priority": 6},
]

# ==================== SETUP VALIDATION ====================

def check_environment():
    """Validate system environment before starting"""
    print("üîç Validating environment...")
    
    # Check Python version
    if sys.version_info < (3, 8):
        print("‚ùå Python 3.8+ required")
        return False
    
    # Check GPU
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9
        print(f"‚úÖ GPU: {gpu_name} ({gpu_mem:.1f} GB)")
        
        if gpu_mem < 8:
            print("‚ö†Ô∏è  GPU memory < 8GB - may need to reduce batch_size")
    else:
        print("‚ö†Ô∏è  No GPU detected - training will be very slow")
        # Removed interactive check for automation
    
    # Check disk space
    free_gb = shutil.disk_usage(".").free // (1024**3)
    print(f"üíæ Free disk space: {free_gb}GB")
    if free_gb < 5:
        print("‚ö†Ô∏è  Low disk space - may run out during training")
    
    # Check HF token
    if not HF_TOKEN:
        print("‚ö†Ô∏è  HF_TOKEN not set. Models will not be uploaded to Hugging Face.")
    else:
        print("‚úÖ HF_TOKEN found")
    
    # Check wandb - either env var or logged in via wandb login
    wandb_key = os.getenv("WANDB_API_KEY")
    if not wandb_key:
        try:
            import wandb
            if wandb.api.default_entity:
                print(f"‚úÖ W&B: Logged in as {wandb.api.default_entity}")
            else:
                print("‚ö†Ô∏è  WANDB_API_KEY not set - runs will be anonymous")
        except:
            print("‚ö†Ô∏è  WANDB_API_KEY not set - runs will be anonymous")
    else:
        print("‚úÖ W&B: API key found in environment")
    
    # Check all config files exist
    for exp in EXPERIMENTS:
        if not os.path.exists(exp['config']):
            print(f"‚ùå Config not found: {exp['config']}")
            return False
    
    print("‚úÖ Environment validation passed\n")
    return True

def setup_huggingface():
    """Create all HF repositories if they don't exist"""
    print("ü§ó Setting up Hugging Face repositories...")
    
    from huggingface_hub import create_repo
    repos = [
        f"{YOUR_HF_USERNAME}/sac-lunarlander-v3",
        f"{YOUR_HF_USERNAME}/td3-lunarlander-v3",
        f"{YOUR_HF_USERNAME}/ppo-lunarlander-v3",
        f"{YOUR_HF_USERNAME}/sac-carracing-cnn",
        f"{YOUR_HF_USERNAME}/td3-carracing-cnn",
        f"{YOUR_HF_USERNAME}/ppo-carracing-cnn"
    ]
    
    for repo in repos:
        try:
            create_repo(repo, exist_ok=True, token=HF_TOKEN, repo_type="model")
            print(f"‚úÖ {repo}")
        except Exception as e:
            print(f"‚ö†Ô∏è  {repo}: {e}")
    
    print("‚úÖ HF setup complete\n")

# ==================== EXPERIMENT RUNNER ====================

def run_experiment(exp: Dict[str, Any], log_file) -> bool:
    """Run a single experiment with crash recovery"""
    algo = exp['algo']
    env = exp['env']
    config_path = exp['config']
    
    print(f"\n{'='*70}", file=log_file)
    print(f"üöÄ Starting: {algo} on {env}", file=log_file)
    print(f"{'='*70}\n", file=log_file)
    log_file.flush()
    
    # Check if already completed
    completion_marker = f"models/{algo}_{env.replace('-', '_')}_completed.txt"
    if os.path.exists(completion_marker):
        print(f"‚ö†Ô∏è  Already completed - skipping {algo}_{env}", file=log_file)
        return True
    
    # Check if interrupted (resume)
    checkpoint_path = f"models/{algo}_{env.replace('-', '_')}_checkpoint.pth"
    if os.path.exists(checkpoint_path):
        print(f"üìç Found checkpoint - resuming from {checkpoint_path}", file=log_file)
        resume_args = ["--resume", checkpoint_path]
    else:
        resume_args = []
    
    # Build command
    cmd = [
        sys.executable, "train.py",
        "--config", config_path
    ] + resume_args
    
    # Run with timeout and error handling
    start_time = time.time()
    max_runtime = 12 * 3600  # 12 hour timeout per experiment
    
    try:
        # Use Popen for real-time logging
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            encoding='utf-8',
            errors='replace',
            env={**os.environ, "CUDA_VISIBLE_DEVICES": "0", "WANDB_MODE": "online"}  # Force GPU 0 and wandb online
        )
        
        # Stream output to log file
        for line in iter(process.stdout.readline, ''):
            print(line.rstrip(), file=log_file)
            log_file.flush()
            
            # Check for errors in output
            if "CUDA out of memory" in line:
                print(f"‚ùå OOM detected in {algo}_{env} - reducing batch size", file=log_file)
                process.terminate()
                return False
            
            # Check timeout
            if time.time() - start_time > max_runtime:
                print(f"‚è±Ô∏è  Timeout reached for {algo}_{env}", file=log_file)
                process.terminate()
                return False
        
        process.wait()
        
        if process.returncode == 0:
            # Mark as completed
            with open(completion_marker, 'w') as f:
                f.write(f"Completed at {datetime.now()}\n")
            
            print(f"‚úÖ SUCCESS: {algo}_{env}", file=log_file)
            return True
        else:
            print(f"‚ùå FAILED: {algo}_{env} (exit code {process.returncode})", file=log_file)
            return False
            
    except Exception as e:
        print(f"üí• CRASH in {algo}_{env}: {e}", file=log_file)
        traceback.print_exc(file=log_file)
        return False

# ==================== MAIN ORCHESTRATOR ====================

class MasterRunner:
    def __init__(self):
        self.log_dir = Path("logs")
        self.log_dir.mkdir(exist_ok=True)
        self.master_log = open(self.log_dir / "master.log", "a", encoding='utf-8')  # Add encoding='utf-8'
        
        # Status tracking
        self.status_file = Path("logs/experiment_status.yaml")
        if self.status_file.exists():
            with open(self.status_file, 'r') as f:
                self.status = yaml.safe_load(f)
        else:
            self.status = {f"{e['algo']}_{e['env']}": "pending" for e in EXPERIMENTS}
    
    def log(self, message):
        """Log with timestamp"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        line = f"[{timestamp}] {message}"
        print(line)
        print(line, file=self.master_log)
        self.master_log.flush()
    
    def save_status(self):
        """Save current experiment status"""
        with open(self.status_file, 'w') as f:
            yaml.dump(self.status, f)
    
    def run_all(self, resume=False):
        """Run all experiments sequentially"""
        self.log("="*70)
        self.log("ü§ñ MASTER RUNNER STARTED")
        self.log("="*70)
        self.log(f"Total experiments: {len(EXPERIMENTS)}")
        self.log(f"Resume mode: {resume}")
        self.log("="*70 + "\n")
        
        # Sort by priority
        experiments = sorted(EXPERIMENTS, key=lambda x: x['priority'])
        
        for i, exp in enumerate(experiments, 1):
            exp_key = f"{exp['algo']}_{exp['env']}"
            
            # Skip if already completed and not resuming
            if self.status.get(exp_key) == "completed" and not resume:
                self.log(f"‚è≠Ô∏è  Skipping completed: {exp_key}")
                continue
            
            # Skip if failed and not resuming
            if self.status.get(exp_key) == "failed" and not resume:
                self.log(f"‚è≠Ô∏è  Skipping failed: {exp_key}")
                continue
            
            self.log(f"\nüìä Experiment {i}/{len(experiments)}: {exp_key}")
            self.status[exp_key] = "running"
            self.save_status()
            
            # Run experiment
            success = run_experiment(exp, self.master_log)
            
            if success:
                self.status[exp_key] = "completed"
                self.log(f"‚úÖ Marked as completed: {exp_key}")
            else:
                self.status[exp_key] = "failed"
                self.log(f"‚ùå Marked as failed: {exp_key}")
            
            self.save_status()
            
            # # Cooldown between experiments
            # if i < len(experiments):
            #     self.log("\nüí§ Cooling down for 5 minutes...")
            #     time.sleep(300)  # Prevent GPU overheating
        
        # Final summary
        self.print_summary()
        
        # Generate final report
        self.generate_report()
        
        self.log("\nüéâ ALL EXPERIMENTS FINISHED!")
        self.master_log.close()
    
    def print_summary(self):
        """Print final status summary"""
        self.log("\n" + "="*70)
        self.log("üìã FINAL STATUS SUMMARY")
        self.log("="*70)
        
        completed = sum(1 for s in self.status.values() if s == "completed")
        failed = sum(1 for s in self.status.values() if s == "failed")
        pending = sum(1 for s in self.status.values() if s == "pending")
        
        self.log(f"‚úÖ Completed: {completed}/{len(EXPERIMENTS)}")
        self.log(f"‚ùå Failed: {failed}/{len(EXPERIMENTS)}")
        self.log(f"‚è≥ Pending: {pending}/{len(EXPERIMENTS)}")
        
        if failed > 0:
            self.log("\nFailed experiments:")
            for exp, status in self.status.items():
                if status == "failed":
                    self.log(f"  - {exp}")
        
        self.log("="*70)
    
    def generate_report(self):
        """Generate a final report from wandb data"""
        self.log("\nüìÑ Generating final report...")
        
        try:
            import wandb
            api = wandb.Api()
            
            report_data = []
            for exp in EXPERIMENTS:
                runs = api.runs(
                    WANDB_PROJECT,
                    {"config.algo": exp['algo'], "config.env_id": exp['env']}
                )
                
                if runs:
                    best_run = max(runs, key=lambda r: r.summary.get('eval/mean_reward', -float('inf')))
                    report_data.append({
                        'algorithm': exp['algo'],
                        'environment': exp['env'],
                        'best_score': best_run.summary.get('eval/mean_reward', 'N/A'),
                        'wandb_url': best_run.url
                    })
            
            # Save report
            with open("logs/final_report.md", "w") as f:
                f.write("# CMPS458 Assignment 4 - Final Results\n\n")
                f.write("## Best Scores\n\n")
                for row in report_data:
                    f.write(f"- **{row['algorithm']}** on **{row['environment']}**: "
                           f"{row['best_score']} ([W&B]({row['wandb_url']}))\n")
            
            self.log("‚úÖ Report saved to logs/final_report.md")
            
        except Exception as e:
            self.log(f"‚ö†Ô∏è  Could not generate report: {e}")

# ==================== MAIN ENTRY POINT ====================

def main():
    parser = argparse.ArgumentParser(description="Autonomous RL Master Runner")
    parser.add_argument("--resume", action="store_true", help="Resume from last checkpoint")
    parser.add_argument("--validate-only", action="store_true", help="Only validate setup")
    args = parser.parse_args()
    
    if args.validate_only:
        print("üîç Running validation only...")
        if not check_environment():
            exit(1)
        exit(0)
    
    # Phase 1: Validate environment
    if not check_environment():
        print("\n‚ùå Environment validation failed. Fix issues and retry.")
        exit(1)
    
    # Phase 2: Setup HF
    setup_huggingface()
    
    # Phase 3: Create directories
    Path("models").mkdir(exist_ok=True)
    Path("logs").mkdir(exist_ok=True)
    
    # Phase 4: Run experiments
    runner = MasterRunner()
    runner.run_all(resume=args.resume)
    
    print("\nüéâ Master runner finished! Check logs/master.log for details.")
    print("üìÑ Final report: logs/final_report.md")

if __name__ == "__main__":
    main()